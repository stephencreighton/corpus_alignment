README for corpus_alignment

- Code files
align.rb				master script
xfile.rb				generates an object for each input file containing raw source, source in paragraphs/phrases, and 
						an analysis of the text (using phase_array_item.rb)
phrase_array_item.rb
comparator.rb			loops through first source file: for each valid phrase, attempt to find corresponding "phrase" in 
						other source file and insert into aligned_pairs array; generate confidence score per phrase and overall
aligned_pairs.rb
aligned_pairs_item.rb

- Demo script
go

- Input files
en_conf_short.txt		First few paragraphs of Augustine's Confessions in English
fr_conf_short.txt		Same in French
gutenberg_intro_en.txt	Pulled off of gutenberg.org, in English
gutenberg_intro_fr.txt	Same in French
en_conf.txt				Full Confessions in English
de_conf.txt				Same in German

- Output files (generated by ./go)
align_en_conf_short.txt_with_fr_conf_short.txt.out				alignment of en_conf_short.txt with fr_conf_short.txt
align_fr_conf_short.txt_with_en_conf_short.txt.out				same, but using the French file as the basis for alignment
align_gutenberg_intro_en.txt_with_gutenberg_intro_fr.txt.out	etc.
align_en_conf.txt_with_de_conf.txt.out


Notes:
- You provided the initial assumption that the structures will be the same for file pairs that are supposed to be the 
same doc with good translation.  This prototype was developed with that assumption, and adds some additional auto-cleanup 
(ignore extraneous blank lines, handle a small amount of extraneous material in the middle of the text, ignore extraneous 
material at the end of either file).  This works very well on file pairs that fit this description.
- Given the above assumption, this prototype works strictly from the raw text; no additional manual massaging (insertion
of tags, etc) is required.
- The first four tests run by "go" show system performance on well-translated document pairs.  The eng_conf.txt / de_conf.txt 
pairing is a good example of the results when the text structure has a higher degree of variance - the prototype goes as far 
as it can and throws away the rest.  This can be addressed by the process described below.
- The comparator right now uses phrase length and a standard expected text expansion factor (e.g. 1.2 for French vs English) 
for finding "similar" phrases in the two files, and for identifying document structure.  While this works very well on 
highly-aligned documents, I have developed a far more robust algorithm that I propose implementing in the next rev; this 
is based on a fair amount of research, and is detailed below.  Based on the reported performance of similar algorithms, 
this promises to largely obviate the need for using an external engine to verify key word matches.


Iterative Distribution-Based Comparator Process:
-	[Note:  this assumes that the doc pairs are EN/XX, where XX is some other language; therefore the alternate language 
will be referred to below as AA.]
-	Construct a SentenceTable for each text by decomposing texts into “sentences”.
-	Construct  a DistributionTable for each text:  a list of the words in that text, containing the sentence numbers where 
that word is found.
-	Loop:
	o	Select proposed sentence “pairs” (this may actually be 1:many, as described  immediately below):  
		•	First pass:  choose first and last sentences of each text (on the assumption that they will match); these are 
		the only known Anchors at this time.  Plus…
		•	Choose additional sentences as follows:
			•	For each existing consecutive pair of EN Anchors, choose the EN sentence exactly between those two Anchors.  
			•	Choose the AA sentence exactly in the middle of the two corresponding consecutive AA Anchors.
			•	Calculate how many sentences lie between the two selected AA Anchors; calculate n where n = the sq rt of 
			that number; add the n/2 sentences immediately preceding and following the chosen AA sentence.  [Standard deviation]
			Note:  as long as the sentences chosen are not existing Anchors, and do not cross an existing Anchor.
	o	For each proposed sentence pair:
		•	Using the DistributionTables, identify proposed matching word pairs:  find the words in the sentence pair that 
		have the highest DistributionSimilarity score:
			•	This is a function of the number of corresponding sentences in which they occur and the total number of 
			occurences of each, specifically
				2c / (a + b)
			where a = number of occurences of the EN word in EN text
			b = number of occurences of the AA word in AA text
			c = number of times the words occur in both EN and AA texta (i.e. in corresponding sentence pairs).
			•	[Note:  this is a standard statistically distance measure, sometimes called Sorenson index or Czekanowski index.]
			•	[Note:  real-world measurements may support setting an upper limit on this, e.g. the location of the 
			corresponding AA sentence for a given EN sentence is never more than 10 sentences away from the central sentence.]
		•	If the proposed matching word pairs pass the WordSimilarityThreshhold, add them to the WordPairList, along with 
		their DistributionSimilarity score and their frequencies in their respective texts.
			•	Note that frequency is important, since if the pair only occurs once, even if the similarity score is perfect, 
			there is little confidence in their alignment.  
		•	For each matching word pair, update the similarity score on all associated sentences.  
			•	When a sentence passes the SentenceSimilarityThreshhold, add it to the SentencePairList.  Initial 
			threshhold might be (>7 word matches) && (similarity > 0.8)
			•	Use sentences in the SentencePairList as new Anchors for subsequent passes.  These will converge, providing a 
			complete mapping of the valid portions of the two documents.



Subsequent phases:
-	Add support for morphology:  normalize words by statistically identifying prefixes and suffixes, removing them to create 
new root words, and adding the new root words to the DistributionList, along with their distributions.  This should 
significantly immprove word alignment.
- Add GUI for file selection and options selection - there are a number of fixed values in the prototype that could be user-set
variables, allowing for finer tuning of the process based on the peculiarities in the particular texts.
- Add support for identifying and proposing possible reordered matches (phrases/sentences inside a paragraph, paragraphs 
within document).
- Based on performance of new comparator process, might utilize POS tools, lexicons/dictionaries, and/or external engines 
to further verify key word matches.
- Integrate with existing side-by-side display for human verification.
- Integrate with existing corpus database.
- Integrate industry-standard MT evaluation tools/algorithms (e.g. BLEU).





